![BeyondAI Banner for Research Projects](../BeyondAI_Banner_Research_Projects_2024.png)

# Non - Linear Classifiers

Linear classifiers are limited by their assumption of a linear relationship between features and class labels. This makes them ineffective when the data exhibits non-linear relationships.

**Performance Evaluation:** </br>
The goal of classifier evaluation is to understand how well each model performs under different circumstances. We use various performance metrics to assess the effectiveness of each classifier. These metrics are:

Accuracy: Measures the proportion of correct predictions over the total predictions. While useful, it can be misleading when the dataset is imbalanced.

Precision: The proportion of true positive predictions out of all positive predictions made. This metric is critical when false positives are costly.

Recall: The proportion of true positive predictions out of all actual positives. This metric is useful when false negatives are costly.

F1-Score: The harmonic mean of Precision and Recall, which balances the trade-off between them. It is particularly useful when dealing with imbalanced classes.

Training Time: The computational cost of training the model, which can be significant for non-linear classifiers on large datasets.

Testing Time: The time taken by the model to make predictions on new (testing) data, which is important for real-time applications.

1. motivating your research question
2. stating your research question
3. explaining your method and implementation
4. Briefly mention and discuss your results
5. Draw your conclusions

> The research poster for this project can be found in the [BeyondAI Proceedings 2024](https://thinkingbeyond.education/beyondai_proceedings_2024/).
